{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdfs3 import *  \n",
    "# from pyspark import SparkFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs = HDFileSystem(host='localhost', port=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hdfs_h5_files(basedir, fs):\n",
    "    \"\"\"\n",
    "    From a root directory, go through all subdirectories\n",
    "    and find all files with the given extension.\n",
    "    Return all absolute paths in a list.\n",
    "    - basedir is base path name\n",
    "    - fs is HDFS\n",
    "    \"\"\"\n",
    "    root = fs.ls(basedir)\n",
    "    h5_list = []\n",
    "    for subdir in root:\n",
    "        for subsubdir in fs.ls(subdir):\n",
    "            for h5_dir in fs.ls(subsubdir):\n",
    "                h5_list += fs.ls(h5_dir)\n",
    "    return h5_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_list = get_hdfs_h5_files(\"/h5_data\", hdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "\n",
    "with open('cache.csv', 'w') as writeFile:\n",
    "    for i in h5_list:\n",
    "        writeFile.write(i)\n",
    "        writeFile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert h5 format to csv\n",
    "\n",
    "```python\n",
    "get_num_songs(h5)         # number of songs in the file\n",
    "get_title(h5)             # name of song\n",
    "get_song_hotttnesss(h5)   # hotness of a song\n",
    "get_duration(h5)          # duration of song\n",
    "get_energy(h5)            # energy\n",
    "get_tempo(h5)             # tempo (speed of song?)\n",
    "get_release(h5)           # album name\n",
    "get_artist_name(h5)       # artist name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PythonSrc.hdf5_getters import *\n",
    "from PythonSrc.utils import get_all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5_to_csv(flist):\n",
    "    df = pd.DataFrame(columns=['title', 'artist', 'album', 'hotness', 'duration', 'energy', 'tempo'])\n",
    "    index = 0\n",
    "    for fi in flist:\n",
    "        h5 = open_h5_file_read(fi)\n",
    "        df.loc[index] = [get_title(h5).decode('UTF-8'), get_artist_name(h5).decode('UTF-8'), \n",
    "                     get_release(h5).decode('UTF-8'), get_song_hotttnesss(h5), get_duration(h5), \n",
    "                     get_energy(h5), get_tempo(h5)]\n",
    "        index += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get absolute file address lists\n",
    "paths = get_all_files('F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = h5_to_csv(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File('F/A/A/TRFAAAR128F932296C.h5','r')\n",
    "# for i in f.keys():\n",
    "#     print(i)\n",
    "    \n",
    "# for k, v in f.items():\n",
    "#     print(\"----------\")\n",
    "#     print(k)\n",
    "#     print(\"----------\")\n",
    "#     for k1, v1 in v.items():\n",
    "#         print(k1, v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('F/A/A/TRFAAAR128F932296C.h5','rb') as file: # b is important -> binary\n",
    "    fileContent = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                            n_informative=2, n_redundant=0,\n",
    "                            random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.66853167, -1.29901346,  0.2746472 , -0.60362044],\n",
       "       [-2.9728827 , -1.08878294,  0.70885958,  0.42281857],\n",
       "       [-0.59614125, -1.37007001, -3.11685659,  0.64445203],\n",
       "       ..., \n",
       "       [ 0.91711204,  1.10596645,  0.86766522, -2.25625012],\n",
       "       [ 0.10027664,  1.45875846, -0.44360274, -0.67002328],\n",
       "       [ 1.0415229 , -0.01987143,  0.15216419, -1.9405334 ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
